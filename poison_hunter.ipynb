{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfd5abec-3ca3-4613-810e-2470809d01da",
   "metadata": {},
   "source": [
    "### POISON HUNTER IMPLEMENTATION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621b6a18-ab9e-4a66-aa94-76e1776e6829",
   "metadata": {},
   "source": [
    "## DATA PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7106eae0-428b-4ca0-b2b5-2eb6855b2ae3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df2c7d72cbf463e8293c74590c48ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba127d1b78034891bf7dd73b09aafcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bigquery step_1_df\n",
    "SELECT\n",
    "  block_number,\n",
    "  block_timestamp,\n",
    "  token_address,\n",
    "  from_address,\n",
    "  to_address,\n",
    "  value,\n",
    "  CAST(value AS NUMERIC)/1000000 AS value_usd,\n",
    "  transaction_hash\n",
    "FROM `bigquery-public-data.crypto_ethereum.token_transfers`\n",
    "WHERE token_address IN (\n",
    "    '0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48', -- USDC\n",
    "    '0xdac17f958d2ee523a2206206994597c13d831ec7'  -- USDT\n",
    ")\n",
    "AND block_timestamp >= TIMESTAMP(\"2024-07-01\")\n",
    "AND block_timestamp < TIMESTAMP(\"2024-08-01\")\n",
    "AND from_address != to_address\n",
    "ORDER BY block_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "677872d8-97eb-4df5-a32b-f7a1e21576af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>block_timestamp</th>\n",
       "      <th>token_address</th>\n",
       "      <th>from_address</th>\n",
       "      <th>to_address</th>\n",
       "      <th>value</th>\n",
       "      <th>value_usd</th>\n",
       "      <th>transaction_hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20207949</td>\n",
       "      <td>2024-07-01 00:00:11+00:00</td>\n",
       "      <td>0xdac17f958d2ee523a2206206994597c13d831ec7</td>\n",
       "      <td>0x3ec6be020a96510719c608b966a6a9c4d8451e2d</td>\n",
       "      <td>0x6f0bdcbeb74b568171d14884151cefdfe6e67e82</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10.000000000</td>\n",
       "      <td>0xdc043489abbb019e2f01c05b21c84954c8462bf4e725...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20207949</td>\n",
       "      <td>2024-07-01 00:00:11+00:00</td>\n",
       "      <td>0xdac17f958d2ee523a2206206994597c13d831ec7</td>\n",
       "      <td>0xb921807735d83f0d93c0395f1a10edb06e016da9</td>\n",
       "      <td>0x7563758243a262e96880f178aee7817dcf47ab0f</td>\n",
       "      <td>340573867</td>\n",
       "      <td>340.573867000</td>\n",
       "      <td>0x9a7a83cb918efa64d905867865bc7d6d46357d97225a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20207949</td>\n",
       "      <td>2024-07-01 00:00:11+00:00</td>\n",
       "      <td>0xdac17f958d2ee523a2206206994597c13d831ec7</td>\n",
       "      <td>0xa9d1e08c7793af67e9d92fe308d5697fb81d3e43</td>\n",
       "      <td>0x5181ef4d130be083624aadb2229ffcf440a53f97</td>\n",
       "      <td>497411600</td>\n",
       "      <td>497.411600000</td>\n",
       "      <td>0x43c631eaa109f6957376cb67fd4dc0692e737bc89c94...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20207949</td>\n",
       "      <td>2024-07-01 00:00:11+00:00</td>\n",
       "      <td>0xdac17f958d2ee523a2206206994597c13d831ec7</td>\n",
       "      <td>0xc05352bd44fb0d0beab927645470a27f460a106f</td>\n",
       "      <td>0x4f9fc4e0b79c1cbf16e68863ad5e9de6a94a346c</td>\n",
       "      <td>758456785</td>\n",
       "      <td>758.456785000</td>\n",
       "      <td>0x654f452c914a1afa7ba5155faaf60e5f5b1f61c82ee5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20207949</td>\n",
       "      <td>2024-07-01 00:00:11+00:00</td>\n",
       "      <td>0xdac17f958d2ee523a2206206994597c13d831ec7</td>\n",
       "      <td>0xba340a75c9398d9d99c1fe16c6500713cedbf6a7</td>\n",
       "      <td>0x7563758243a262e96880f178aee7817dcf47ab0f</td>\n",
       "      <td>266890000</td>\n",
       "      <td>266.890000000</td>\n",
       "      <td>0x70171e21c55003637f9352a8be75f37ee28a6964830e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   block_number           block_timestamp  \\\n",
       "0      20207949 2024-07-01 00:00:11+00:00   \n",
       "1      20207949 2024-07-01 00:00:11+00:00   \n",
       "2      20207949 2024-07-01 00:00:11+00:00   \n",
       "3      20207949 2024-07-01 00:00:11+00:00   \n",
       "4      20207949 2024-07-01 00:00:11+00:00   \n",
       "\n",
       "                                token_address  \\\n",
       "0  0xdac17f958d2ee523a2206206994597c13d831ec7   \n",
       "1  0xdac17f958d2ee523a2206206994597c13d831ec7   \n",
       "2  0xdac17f958d2ee523a2206206994597c13d831ec7   \n",
       "3  0xdac17f958d2ee523a2206206994597c13d831ec7   \n",
       "4  0xdac17f958d2ee523a2206206994597c13d831ec7   \n",
       "\n",
       "                                 from_address  \\\n",
       "0  0x3ec6be020a96510719c608b966a6a9c4d8451e2d   \n",
       "1  0xb921807735d83f0d93c0395f1a10edb06e016da9   \n",
       "2  0xa9d1e08c7793af67e9d92fe308d5697fb81d3e43   \n",
       "3  0xc05352bd44fb0d0beab927645470a27f460a106f   \n",
       "4  0xba340a75c9398d9d99c1fe16c6500713cedbf6a7   \n",
       "\n",
       "                                   to_address      value      value_usd  \\\n",
       "0  0x6f0bdcbeb74b568171d14884151cefdfe6e67e82   10000000   10.000000000   \n",
       "1  0x7563758243a262e96880f178aee7817dcf47ab0f  340573867  340.573867000   \n",
       "2  0x5181ef4d130be083624aadb2229ffcf440a53f97  497411600  497.411600000   \n",
       "3  0x4f9fc4e0b79c1cbf16e68863ad5e9de6a94a346c  758456785  758.456785000   \n",
       "4  0x7563758243a262e96880f178aee7817dcf47ab0f  266890000  266.890000000   \n",
       "\n",
       "                                    transaction_hash  \n",
       "0  0xdc043489abbb019e2f01c05b21c84954c8462bf4e725...  \n",
       "1  0x9a7a83cb918efa64d905867865bc7d6d46357d97225a...  \n",
       "2  0x43c631eaa109f6957376cb67fd4dc0692e737bc89c94...  \n",
       "3  0x654f452c914a1afa7ba5155faaf60e5f5b1f61c82ee5...  \n",
       "4  0x70171e21c55003637f9352a8be75f37ee28a6964830e...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47aaa899-125a-4b47-ad69-f4eb89cb7fd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of txns: 7291135\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of txns: {len(step_1_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fc7b304-cc9d-4bb2-8331-a3e91ab15005",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "min_block = step_1_df['block_number'].min()\n",
    "max_block = step_1_df['block_number'].max()\n",
    "\n",
    "def filter_by_block(start_block: int, end_block: int, df: pd.DataFrame = step_1_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters a pandas DataFrame by block_number range and returns a new DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing a 'block_number' column.\n",
    "        start_block (int): Minimum block_number (inclusive).\n",
    "        end_block (int): Maximum block_number (inclusive).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure block_number column exists\n",
    "    if 'block_number' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain a 'block_number' column.\")\n",
    "    \n",
    "    filtered_df = df[(df['block_number'] >= start_block) & (df['block_number'] <= end_block)]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ff0d490b-db17-43d6-ab0e-f99c2700a02f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min block: 20207949\n",
      "max block: 20429972\n"
     ]
    }
   ],
   "source": [
    "print(f\"min block: {min_block}\")\n",
    "print(f\"max block: {max_block}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ff3c0d5-3bc7-46c7-98df-4c00bab5810a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Set, Any\n",
    "# takes a window of transactions and a block with the original txn & identifies all zero-value and tiny-dusty attack\n",
    "def step2_vectorized(window_dataframe, block_1):\n",
    "    \n",
    "    victim_set = set(block_1['from_address'])\n",
    "    \n",
    "    # Build victim -> tx_hashes mapping\n",
    "    victim_to_tx_hashes = block_1.groupby('from_address')['transaction_hash'].apply(set).to_dict()\n",
    "    \n",
    "    # Vectorized conditions\n",
    "    mask_zero = (window_dataframe['value_usd'] == 0) & (window_dataframe['from_address'].isin(victim_set))\n",
    "    mask_dust = (window_dataframe['value_usd'] > 0) & (window_dataframe['value_usd'] <= 1) & (window_dataframe['to_address'].isin(victim_set))\n",
    "    \n",
    "    combined_mask = mask_zero | mask_dust\n",
    "    \n",
    "    # Early return if no matches\n",
    "    if not combined_mask.any():\n",
    "        return pd.DataFrame(columns=list(window_dataframe.columns) + ['attacker_address', 'victim_address', 'victim_tx_hash', 'attack_type'])\n",
    "    \n",
    "    # Filter matching rows\n",
    "    suspicious_transactions = window_dataframe[combined_mask].copy()\n",
    "    \n",
    "    # Get the mask subset for proper alignment\n",
    "    mask_zero_subset = mask_zero[combined_mask]\n",
    "    \n",
    "    # Set attacker address based on which condition matched\n",
    "    suspicious_transactions['attacker_address'] = np.where(\n",
    "        mask_zero_subset,\n",
    "        suspicious_transactions['to_address'],\n",
    "        suspicious_transactions['from_address']\n",
    "    )\n",
    "    \n",
    "    # Set victim address (opposite of attacker)\n",
    "    suspicious_transactions['victim_address'] = np.where(\n",
    "        mask_zero_subset,\n",
    "        suspicious_transactions['from_address'],\n",
    "        suspicious_transactions['to_address']\n",
    "    )\n",
    "    \n",
    "    # Set victim tx hash using the mapping\n",
    "    suspicious_transactions['victim_tx_hash'] = suspicious_transactions['victim_address'].map(\n",
    "        lambda addr: victim_to_tx_hashes.get(addr, set())\n",
    "    )\n",
    "    \n",
    "    # Set attack type\n",
    "    suspicious_transactions['attack_type'] = np.where(\n",
    "        mask_zero_subset,\n",
    "        'zero',\n",
    "        'dust'\n",
    "    )\n",
    "    \n",
    "    return suspicious_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4b8c99c2-b660-4fd8-952b-14e1faf61dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started at 1764439369.4527228\n",
      "end time: 1764439449.824726\n"
     ]
    }
   ],
   "source": [
    "BLOCK_WDOW = 100\n",
    "# transaction_set = step_1_df\n",
    "import time\n",
    "\n",
    "start = time.time()  # record start time\n",
    "sus_txns = []\n",
    "print(f\"started at {start}\")\n",
    "for block_num in range(min_block,min_block+1000):\n",
    "    victim_block = filter_by_block(block_num,block_num)\n",
    "    search_window = filter_by_block(block_num+1,block_num+BLOCK_WDOW+1)\n",
    "    new_df = step2_vectorized(search_window, victim_block)\n",
    "    if not new_df.empty:\n",
    "        sus_txns.append(new_df)\n",
    "end = time.time()    # record end time\n",
    "combined_df_vector = pd.concat(sus_txns, ignore_index=True)\n",
    "print(f\"end time: {end}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "948c80e0-063f-4f8d-b939-477f48b909e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701, 12)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_vector.sort_values(\n",
    "    by=\"transaction_hash\",\n",
    "    key=lambda col: col.astype(str)\n",
    ").reset_index(drop=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dedcb6a-9ba3-434c-98eb-bd8d449a1eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed for 1000 blocks: 8.994812488555908 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# -------------------------------\n",
    "# 1. DEFINE THE BLOCK RANGE\n",
    "# -------------------------------\n",
    "start = time.time()  # record start time\n",
    "NUM_BLOCKS = 1000\n",
    "victim_blocks = np.arange(min_block, min_block + NUM_BLOCKS)\n",
    "\n",
    "# Victim df = all transactions in those blocks\n",
    "victim_df = step_1_df[step_1_df['block_number'].isin(victim_blocks)].copy()\n",
    "\n",
    "# Window df = all transactions that could appear in any search window\n",
    "search_min = min_block + 1\n",
    "search_max = (min_block + NUM_BLOCKS - 1) + BLOCK_WDOW + 1 \n",
    "\n",
    "window_df = step_1_df[\n",
    "    (step_1_df['block_number'] >= search_min) &\n",
    "    (step_1_df['block_number'] <= search_max)\n",
    "].copy()\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 1. BUILD MAPPING: search_block → victim_block(s)\n",
    "# ----------------------------------------\n",
    "# For each unique search block in window_df, compute which victim blocks it should pair with.\n",
    "search_unique_blocks = window_df['block_number'].unique()\n",
    "\n",
    "# For each search block B_s, valid victims satisfy:\n",
    "#   B_v ∈ [B_s - BLOCK_WDOW, B_s - 1]\n",
    "#   and B_v is within our victim range\n",
    "mapping_rows = []\n",
    "for b_s in search_unique_blocks:\n",
    "    v_low = b_s - BLOCK_WDOW - 1  # changed from b_s - BLOCK_WDOW\n",
    "    v_high = b_s - 1\n",
    "\n",
    "    # intersect with our victim blocks\n",
    "    valid_victims = victim_blocks[\n",
    "        (victim_blocks >= v_low) & (victim_blocks <= v_high)\n",
    "    ]\n",
    "\n",
    "    for v in valid_victims:\n",
    "        mapping_rows.append((b_s, v))\n",
    "\n",
    "block_map = pd.DataFrame(mapping_rows, columns=['search_block', 'victim_block'])\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. MERGE THE MAPPING WITH window_df\n",
    "# ----------------------------------------\n",
    "# Many window_df rows share the same block → they will inherit the same victim_block list\n",
    "window_df2 = window_df.merge(\n",
    "    block_map,\n",
    "    left_on='block_number',\n",
    "    right_on='search_block',\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "# Clean up helper col\n",
    "window_df2 = window_df2.drop(columns=['search_block'])\n",
    "\n",
    "# ----------------------------------------\n",
    "# 3. FOR EACH victim_block, extract its victims\n",
    "# ----------------------------------------\n",
    "# This avoids millions of repeated filters.\n",
    "victim_groups = {\n",
    "    blk: grp for blk, grp in victim_df.groupby('block_number')\n",
    "}\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. RUN step2_vectorized in BULK\n",
    "# ----------------------------------------\n",
    "# We now have a single giant window table, but rows know their victim_block.\n",
    "results = []\n",
    "\n",
    "for v_block, win_grp in window_df2.groupby('victim_block'):\n",
    "    victim_block_df = victim_groups.get(v_block)\n",
    "    if victim_block_df is None:\n",
    "        continue\n",
    "\n",
    "    out = step2_vectorized(win_grp, victim_block_df)\n",
    "    if not out.empty:\n",
    "        out['victim_block_number'] = v_block\n",
    "        results.append(out)\n",
    "\n",
    "# Final output = merged suspicious transactions across ALL blocks\n",
    "step_2_df = pd.concat(results, ignore_index=True) if results else pd.DataFrame()\n",
    "end = time.time()  # record start time\n",
    "print(f\"time elapsed for {NUM_BLOCKS} blocks: {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda74554-d159-464b-9513-c432ac5a1b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701, 14)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_2_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db4b12-d3d0-4a37-8ae5-c944f7795ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m136",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m136"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
